{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXSFabBp6V60RT7VLwHzzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/Computer_Vision/blob/main/TA/baseline_VGG11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DD6HoJRHYn_e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "\n",
        "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/Computer_Vision/ActiveLearning/CUB_200_2011_repackage_class50')\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYah-1LeZKv8",
        "outputId": "ef947831-6236-490f-d288-e7ee87e2f1b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/MyDrive/Colab Notebooks/Computer_Vision/ActiveLearning/CUB_200_2011_repackage_class50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Custom Dataset ###\n",
        "class CUB2011(Dataset):\n",
        "    def __init__(self, transform, mode='train'):\n",
        "        self.transform = transform\n",
        "        self.mode = mode\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            self.image_folder = os.listdir('./datasets/train')\n",
        "        elif self.mode == 'valid':\n",
        "            self.image_folder = os.listdir('./datasets/valid')\n",
        "        elif self.mode == 'test':\n",
        "            self.image_folder = os.listdir('./datasets/test')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_folder)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_folder[idx]\n",
        "        img = Image.open(os.path.join('./datasets', self.mode, img_path)).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "\n",
        "        label = img_path.split('_')[-1].split('.')[0]\n",
        "        label = int(label)\n",
        "        return (img, label)"
      ],
      "metadata": {
        "id": "RA53ogElZM6I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Preprocessing ###\n",
        "transforms_train = transforms.Compose([transforms.Resize((448, 448)),\n",
        "                                       transforms.ToTensor()])\n",
        "\n",
        "transforms_valtest = transforms.Compose([transforms.Resize((448, 448)),\n",
        "                                         transforms.ToTensor()])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_set = CUB2011(mode='train',\n",
        "                    transform=transforms_train)\n",
        "val_set = CUB2011(mode='valid',\n",
        "                  transform=transforms_valtest)\n",
        "test_set = CUB2011(mode='test',\n",
        "                   transform=transforms_valtest)\n",
        "\n",
        "print('Num of each dataset:', len(train_set), len(val_set), len(test_set))\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Loaded dataloader\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTrTpCQ-ZQrq",
        "outputId": "3069438e-cdce-423e-dd3d-ac5c6bce5051"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of each dataset: 2360 296 298\n",
            "Loaded dataloader\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Model / Optimizer ###\n",
        "\n",
        "EPOCH = 30\n",
        "lr = 0.1\n",
        "\n",
        "# Use VGG11 model with pre-trained weights\n",
        "model = models.vgg11(pretrained=True)\n",
        "\n",
        "### Transfer Learning ###\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier[6] = nn.Linear(num_features, 50)\n",
        "print(model)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "print(\"Created a learning model and optimizer using VGG11\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKU3kJRTZdO7",
        "outputId": "0f8ff653-48b4-49c7-88cb-38783d06749d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=50, bias=True)\n",
            "  )\n",
            ")\n",
            "Created a learning model and optimizer using VGG11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for i, (image, target) in enumerate(train_loader):\n",
        "        image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "        output = model(image)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss = F.cross_entropy(output, target).to(DEVICE)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(\n",
        "                f'Train Epoch : {epoch} [{i}/{len(train_loader)}]\\tLoss: {train_loss.item():.6f}')\n",
        "\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "cDaRUC6wZbGH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (image, target) in enumerate(val_loader):\n",
        "            image, target = image.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(image)\n",
        "\n",
        "            eval_loss += F.cross_entropy(output,\n",
        "                                         target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    eval_loss /= len(val_loader.dataset)\n",
        "    eval_accuracy = 100 * correct / len(val_loader.dataset)\n",
        "    return eval_loss, eval_accuracy"
      ],
      "metadata": {
        "id": "ccaX73rLZZi0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "    train_loss = train(model, train_loader, optimizer, epoch)\n",
        "    val_loss, val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "    # Save best model\n",
        "    if val_accuracy > best:\n",
        "        best = val_accuracy\n",
        "        torch.save(model.state_dict(), \"./best_model.pth\")\n",
        "\n",
        "    print(f'[{epoch}] Validation Loss : {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NBVd1eYxZYFP",
        "outputId": "c39b11b2-cc4f-4dc8-e4be-56f7ae2162fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch : 0 [0/74]\tLoss: 3.994552\n",
            "Train Epoch : 0 [10/74]\tLoss: 3.889665\n",
            "Train Epoch : 0 [20/74]\tLoss: 3.931416\n",
            "Train Epoch : 0 [30/74]\tLoss: 3.933871\n",
            "Train Epoch : 0 [40/74]\tLoss: 3.892371\n",
            "Train Epoch : 0 [50/74]\tLoss: 3.909106\n",
            "Train Epoch : 0 [60/74]\tLoss: 3.861313\n",
            "Train Epoch : 0 [70/74]\tLoss: 3.884990\n",
            "[0] Validation Loss : 3.8539, Accuracy: 3.7162%\n",
            "Train Epoch : 1 [0/74]\tLoss: 3.849057\n",
            "Train Epoch : 1 [10/74]\tLoss: 3.940177\n",
            "Train Epoch : 1 [20/74]\tLoss: 3.889762\n",
            "Train Epoch : 1 [30/74]\tLoss: 3.907452\n",
            "Train Epoch : 1 [40/74]\tLoss: 3.798785\n",
            "Train Epoch : 1 [50/74]\tLoss: 3.800873\n",
            "Train Epoch : 1 [60/74]\tLoss: 3.682163\n",
            "Train Epoch : 1 [70/74]\tLoss: 3.907063\n",
            "[1] Validation Loss : 3.6166, Accuracy: 7.4324%\n",
            "Train Epoch : 2 [0/74]\tLoss: 3.618076\n",
            "Train Epoch : 2 [10/74]\tLoss: 3.724081\n",
            "Train Epoch : 2 [20/74]\tLoss: 3.198192\n",
            "Train Epoch : 2 [30/74]\tLoss: 3.304050\n",
            "Train Epoch : 2 [40/74]\tLoss: 3.354304\n",
            "Train Epoch : 2 [50/74]\tLoss: 2.914758\n",
            "Train Epoch : 2 [60/74]\tLoss: 2.985941\n",
            "Train Epoch : 2 [70/74]\tLoss: 3.633757\n",
            "[2] Validation Loss : 3.4252, Accuracy: 14.5270%\n",
            "Train Epoch : 3 [0/74]\tLoss: 3.378551\n",
            "Train Epoch : 3 [10/74]\tLoss: 3.101598\n",
            "Train Epoch : 3 [20/74]\tLoss: 2.417564\n",
            "Train Epoch : 3 [30/74]\tLoss: 3.869633\n",
            "Train Epoch : 3 [40/74]\tLoss: 3.245904\n",
            "Train Epoch : 3 [50/74]\tLoss: 2.818750\n",
            "Train Epoch : 3 [60/74]\tLoss: 2.565484\n",
            "Train Epoch : 3 [70/74]\tLoss: 3.572131\n",
            "[3] Validation Loss : 3.0787, Accuracy: 19.2568%\n",
            "Train Epoch : 4 [0/74]\tLoss: 2.742118\n",
            "Train Epoch : 4 [10/74]\tLoss: 2.708714\n",
            "Train Epoch : 4 [20/74]\tLoss: 2.280081\n",
            "Train Epoch : 4 [30/74]\tLoss: 2.773534\n",
            "Train Epoch : 4 [40/74]\tLoss: 2.321053\n",
            "Train Epoch : 4 [50/74]\tLoss: 1.913006\n",
            "Train Epoch : 4 [60/74]\tLoss: 3.211565\n",
            "Train Epoch : 4 [70/74]\tLoss: 2.117919\n",
            "[4] Validation Loss : 2.6287, Accuracy: 30.7432%\n",
            "Train Epoch : 5 [0/74]\tLoss: 2.450978\n",
            "Train Epoch : 5 [10/74]\tLoss: 1.764756\n",
            "Train Epoch : 5 [20/74]\tLoss: 1.345104\n",
            "Train Epoch : 5 [30/74]\tLoss: 3.276504\n",
            "Train Epoch : 5 [40/74]\tLoss: 1.572005\n",
            "Train Epoch : 5 [50/74]\tLoss: 3.295742\n",
            "Train Epoch : 5 [60/74]\tLoss: 3.822177\n",
            "Train Epoch : 5 [70/74]\tLoss: 2.701399\n",
            "[5] Validation Loss : 2.2423, Accuracy: 41.5541%\n",
            "Train Epoch : 6 [0/74]\tLoss: 2.107276\n",
            "Train Epoch : 6 [10/74]\tLoss: 1.991573\n",
            "Train Epoch : 6 [20/74]\tLoss: 1.642507\n",
            "Train Epoch : 6 [30/74]\tLoss: 1.939801\n",
            "Train Epoch : 6 [40/74]\tLoss: 1.467014\n",
            "Train Epoch : 6 [50/74]\tLoss: 2.059669\n",
            "Train Epoch : 6 [60/74]\tLoss: 1.983204\n",
            "Train Epoch : 6 [70/74]\tLoss: 1.418520\n",
            "[6] Validation Loss : 1.3259, Accuracy: 63.1757%\n",
            "Train Epoch : 7 [0/74]\tLoss: 0.711229\n",
            "Train Epoch : 7 [10/74]\tLoss: 1.015089\n",
            "Train Epoch : 7 [20/74]\tLoss: 0.787273\n",
            "Train Epoch : 7 [30/74]\tLoss: 0.990470\n",
            "Train Epoch : 7 [40/74]\tLoss: 0.964613\n",
            "Train Epoch : 7 [50/74]\tLoss: 0.710682\n",
            "Train Epoch : 7 [60/74]\tLoss: 1.058161\n",
            "Train Epoch : 7 [70/74]\tLoss: 1.624228\n",
            "[7] Validation Loss : 1.8820, Accuracy: 54.7297%\n",
            "Train Epoch : 8 [0/74]\tLoss: 1.147273\n",
            "Train Epoch : 8 [10/74]\tLoss: 0.261476\n",
            "Train Epoch : 8 [20/74]\tLoss: 0.705736\n",
            "Train Epoch : 8 [30/74]\tLoss: 0.757766\n",
            "Train Epoch : 8 [40/74]\tLoss: 1.058151\n",
            "Train Epoch : 8 [50/74]\tLoss: 0.882077\n",
            "Train Epoch : 8 [60/74]\tLoss: 0.392101\n",
            "Train Epoch : 8 [70/74]\tLoss: 0.425697\n",
            "[8] Validation Loss : 1.2314, Accuracy: 68.9189%\n",
            "Train Epoch : 9 [0/74]\tLoss: 0.364492\n",
            "Train Epoch : 9 [10/74]\tLoss: 0.309582\n",
            "Train Epoch : 9 [20/74]\tLoss: 0.060795\n",
            "Train Epoch : 9 [30/74]\tLoss: 0.386816\n",
            "Train Epoch : 9 [40/74]\tLoss: 0.175486\n",
            "Train Epoch : 9 [50/74]\tLoss: 0.230607\n",
            "Train Epoch : 9 [60/74]\tLoss: 1.657900\n",
            "Train Epoch : 9 [70/74]\tLoss: 0.442091\n",
            "[9] Validation Loss : 1.3150, Accuracy: 64.5270%\n",
            "Train Epoch : 10 [0/74]\tLoss: 0.464072\n",
            "Train Epoch : 10 [10/74]\tLoss: 0.098055\n",
            "Train Epoch : 10 [20/74]\tLoss: 0.048177\n",
            "Train Epoch : 10 [30/74]\tLoss: 0.115407\n",
            "Train Epoch : 10 [40/74]\tLoss: 0.046776\n",
            "Train Epoch : 10 [50/74]\tLoss: 0.027239\n",
            "Train Epoch : 10 [60/74]\tLoss: 0.048591\n",
            "Train Epoch : 10 [70/74]\tLoss: 0.280900\n",
            "[10] Validation Loss : 1.9302, Accuracy: 60.8108%\n",
            "Train Epoch : 11 [0/74]\tLoss: 0.613065\n",
            "Train Epoch : 11 [10/74]\tLoss: 0.020491\n",
            "Train Epoch : 11 [20/74]\tLoss: 0.038804\n",
            "Train Epoch : 11 [30/74]\tLoss: 0.070733\n",
            "Train Epoch : 11 [40/74]\tLoss: 0.032082\n",
            "Train Epoch : 11 [50/74]\tLoss: 0.029781\n",
            "Train Epoch : 11 [60/74]\tLoss: 0.119193\n",
            "Train Epoch : 11 [70/74]\tLoss: 0.090279\n",
            "[11] Validation Loss : 1.1764, Accuracy: 72.9730%\n",
            "Train Epoch : 12 [0/74]\tLoss: 0.003490\n",
            "Train Epoch : 12 [10/74]\tLoss: 0.007639\n",
            "Train Epoch : 12 [20/74]\tLoss: 0.017121\n",
            "Train Epoch : 12 [30/74]\tLoss: 0.132666\n",
            "Train Epoch : 12 [40/74]\tLoss: 0.072916\n",
            "Train Epoch : 12 [50/74]\tLoss: 0.060266\n",
            "Train Epoch : 12 [60/74]\tLoss: 0.078680\n",
            "Train Epoch : 12 [70/74]\tLoss: 0.014053\n",
            "[12] Validation Loss : 1.1296, Accuracy: 73.3108%\n",
            "Train Epoch : 13 [0/74]\tLoss: 0.004655\n",
            "Train Epoch : 13 [10/74]\tLoss: 0.004042\n",
            "Train Epoch : 13 [20/74]\tLoss: 0.013151\n",
            "Train Epoch : 13 [30/74]\tLoss: 0.028856\n",
            "Train Epoch : 13 [40/74]\tLoss: 0.010857\n",
            "Train Epoch : 13 [50/74]\tLoss: 0.007696\n",
            "Train Epoch : 13 [60/74]\tLoss: 0.031246\n",
            "Train Epoch : 13 [70/74]\tLoss: 0.211688\n",
            "[13] Validation Loss : 1.8774, Accuracy: 64.5270%\n",
            "Train Epoch : 14 [0/74]\tLoss: 0.145046\n",
            "Train Epoch : 14 [10/74]\tLoss: 0.033489\n",
            "Train Epoch : 14 [20/74]\tLoss: 0.039209\n",
            "Train Epoch : 14 [30/74]\tLoss: 0.201679\n",
            "Train Epoch : 14 [40/74]\tLoss: 0.044262\n",
            "Train Epoch : 14 [50/74]\tLoss: 0.001042\n",
            "Train Epoch : 14 [60/74]\tLoss: 0.029954\n",
            "Train Epoch : 14 [70/74]\tLoss: 0.002393\n",
            "[14] Validation Loss : 1.3732, Accuracy: 71.2838%\n",
            "Train Epoch : 15 [0/74]\tLoss: 0.025651\n",
            "Train Epoch : 15 [10/74]\tLoss: 0.031603\n",
            "Train Epoch : 15 [20/74]\tLoss: 0.000557\n",
            "Train Epoch : 15 [30/74]\tLoss: 0.007758\n",
            "Train Epoch : 15 [40/74]\tLoss: 0.000866\n",
            "Train Epoch : 15 [50/74]\tLoss: 0.020718\n",
            "Train Epoch : 15 [60/74]\tLoss: 0.002843\n",
            "Train Epoch : 15 [70/74]\tLoss: 0.122549\n",
            "[15] Validation Loss : 1.2440, Accuracy: 70.6081%\n",
            "Train Epoch : 16 [0/74]\tLoss: 0.048241\n",
            "Train Epoch : 16 [10/74]\tLoss: 0.034452\n",
            "Train Epoch : 16 [20/74]\tLoss: 0.019534\n",
            "Train Epoch : 16 [30/74]\tLoss: 0.001096\n",
            "Train Epoch : 16 [40/74]\tLoss: 0.000763\n",
            "Train Epoch : 16 [50/74]\tLoss: 0.050556\n",
            "Train Epoch : 16 [60/74]\tLoss: 0.008452\n",
            "Train Epoch : 16 [70/74]\tLoss: 0.000536\n",
            "[16] Validation Loss : 1.1174, Accuracy: 74.6622%\n",
            "Train Epoch : 17 [0/74]\tLoss: 0.005348\n",
            "Train Epoch : 17 [10/74]\tLoss: 0.002006\n",
            "Train Epoch : 17 [20/74]\tLoss: 16302210923891420051800064.000000\n",
            "Train Epoch : 17 [30/74]\tLoss: nan\n",
            "Train Epoch : 17 [40/74]\tLoss: nan\n",
            "Train Epoch : 17 [50/74]\tLoss: nan\n",
            "Train Epoch : 17 [60/74]\tLoss: nan\n",
            "Train Epoch : 17 [70/74]\tLoss: nan\n",
            "[17] Validation Loss : nan, Accuracy: 2.0270%\n",
            "Train Epoch : 18 [0/74]\tLoss: nan\n",
            "Train Epoch : 18 [10/74]\tLoss: nan\n",
            "Train Epoch : 18 [20/74]\tLoss: nan\n",
            "Train Epoch : 18 [30/74]\tLoss: nan\n",
            "Train Epoch : 18 [40/74]\tLoss: nan\n",
            "Train Epoch : 18 [50/74]\tLoss: nan\n",
            "Train Epoch : 18 [60/74]\tLoss: nan\n",
            "Train Epoch : 18 [70/74]\tLoss: nan\n",
            "[18] Validation Loss : nan, Accuracy: 2.0270%\n",
            "Train Epoch : 19 [0/74]\tLoss: nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b327932abbc5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-f441c09fb673>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test result\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "print(f'[FINAL] Test Loss : {test_loss:.4f}, Accuracy: {test_accuracy:.4f}%')\n",
        "\n",
        "end = time.time()\n",
        "elasped_time = end - start\n",
        "\n",
        "\n",
        "print(\"Best Accuracy: \", best)\n",
        "print(f\"Elasped Time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")\n",
        "print(f\"time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")"
      ],
      "metadata": {
        "id": "v2i79cQbZXYC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}